<html>
  <head>
    <meta name="ARModel" content="width=device-width, initial-scale=1" />
	  
    <script src="https://aframe.io/releases/1.3.0/aframe.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/mind-ar@1.2.1/dist/mindar-image-aframe.prod.js"></script>
	<script src="https://cdn.jsdelivr.net/gh/donmccurdy/aframe-extras@v6.1.1/dist/aframe-extras.min.js"></script>
  </head>
  <body>
	  <a-scene mindar-image="imageTargetSrc: https://urginsan.github.io/webTesting/ARModel.mind; uiError:no; uiLoading:no; uiScanning:no" color-space="sRGB" renderer="colorManagement: true, physicallyCorrectLights" vr-mode-ui="enabled: false" device-orientation-permission-ui="enabled: false" id="scene" style="display: block"><!-- style="display: none" >-->
      
	  <a-assets timeout="150000">
	    <a-asset-item 
        id="plane-obj" 
        src="https://urginsan.github.io/webTesting/Shirt_Tshirt.obj"
        timeout="150000"
        ></a-asset-item>


        <a-asset-item
          id="Tshirt"
          src="https://urginsan.github.io/webTesting/Shirt_Tshirt_GLB.glb"
          timeout="150000"
        ></a-asset-item>

        <!--src="https://urginsan.github.io/webTesting/TextureAtlas.mp4"-->
	    <video 
        id="videoTex" 
        loop="true" 
        crossorigin="anonymous" 
        autoplay 
        playsinline 
        src="https://test-videos.co.uk/vids/bigbuckbunny/mp4/h264/360/Big_Buck_Bunny_360_10s_1MB.mp4"
        timeout="150000"
        ></video>
		
      </a-assets>

      <a-camera position="0 0 0" look-controls="enabled: false"></a-camera>
      <a-entity mindar-image-target="targetIndex: 0">
      <!--<a-entity position="0.075 -3.6 -0.3" gltf-model="#tree1"></a-entity>-->

      <a-entity 
      gltf-model="#Tshirt" 
      rotation="0 0 0 " 
      position="0.075 -3.6 -0.3" 
      scale="2.8 2.8 2.8" 
      video-texture="video: #videoTex">
      </a-entity>
	  <!--<a-entity obj-model="obj: #plane-obj;" rotation="0 0 0 " position="0.075 -3.6 -0.3" scale="2.8 2.8 2.8" slideshow></a-entity>-->
      <!-- <a-box position="0 0 0" rotation="0 45 0" slideshow></a-box>-->
         <!--<a-video src="#videoTex" width="1.6" height="0.9" position="0 0 0"></a-video>-->
      
    </a-scene>
	  <div style="display:flex; justify-content:center; align-items:center; height:100vh;">
		  <button type="button" onclick="startPlaying(event)" style="width: 200px; height: 100px; font-size : 18px;" name="show_more">Начать</button>
	  </div>
      
	 <script type="module" src="https://urginsan.github.io/webTesting/video-texture-components.js">
     import {videoTextureComponent, videoTextureCameraRollComponent} from 'https://urginsan.github.io/webTesting/video-texture-components.js'
AFRAME.registerComponent('video-texture', videoTextureComponent)
AFRAME.registerComponent('video-texture-camera-roll', videoTextureCameraRollComponent)

		  function startPlaying(event) {
		  //document.getElementById("scene").style.display = "block";
		  document.getElementById("videoTex").play();
		  //event.target.style.display="none";
		  }
          /*
		  AFRAME.registerComponent("slideshow", {
        init: function () {
            // load the .pngs
            let loader = new THREE.TextureLoader();
            this.pngArray = [];
            let anim1_frames = 20; // total frames
            for (var i = 0; i < anim1_frames; i++) {
                if (i < 10) {
                    //i = '0' + i; // add 0 in front of single digit frames
                }
                this.pngArray.push(loader.load('https://urginsan.github.io/webTesting/sequence1/TextureAtlas_' + i + '.png')); // push TextureLoader loaded with img to array
            };
            
            this.el.addEventListener('model-loaded', e => {
            let mesh = this.el.getObject3D('mesh');
            this.material = mesh.material;

            var i = 0;
            this.id = setInterval(e => {
                if (i >= this.pngArray.length) i = 0;
                this.material.map = this.pngArray[i++];
                this.material.needsUpdate = true;
            }, 1000 / 25);
            })// play at 25fps
        },
        remove: function () {
            clearInterval(this.id);
            // free the memory
            for (let i = 0; i < this.pngArray.length; i++) {
                this.pngArray[i].dispose();
            }
        }
    })
    */

    AFRAME.registerComponent('lambert', {
      schema: {
        color: {
          default: '#0F0'
        },
      },
      init: function() {},
      update: function(oldData) {
        let mesh = this.el.getObject3D('mesh')
        if (!mesh) {
          this.el.addEventListener('model-loaded', e => {
            this.update.call(this, this.data)
          })
          return;
        }
        this.changeColor(mesh, this.data.color);
      },
      changeColor: function(mesh, color) {
        var material = new THREE.MeshLambertMaterial({
          color: color,
        });
        
        mesh.traverse(function(node) {
          if(node.type != "Mesh") return;
          let tmp = node.material
          node.material = material
          tmp.dispose();
        })
      }
    });


    const videoTextureComponent = {
  schema: {
    'video': {type: 'string'},
  },
  init() {
    const video = document.querySelector(this.data.video)
    const texture = new THREE.VideoTexture(video)
    video.play()
    const applyVideoMaterial = (mesh) => {
      if (!mesh) {
        return
      }
      if (mesh.material) {
        // replaces every material that can take a diffuse map with video texture
        mesh.material.map = texture
      }
      mesh.traverse((node) => {
        if (node.isMesh) {
          node.material.map = texture
        }
      })
    }
    this.el.addEventListener(
      'model-loaded', () => applyVideoMaterial(this.el.getObject3D('mesh'))
    )
  },
}
	  </script>
	  
  </body>
</html>
